{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(file):\n",
    "    classes = []\n",
    "    names = []\n",
    "    with open(file, 'r') as f:\n",
    "        header = True\n",
    "        for line in f:\n",
    "            if header:\n",
    "                header = False\n",
    "                continue\n",
    "            n, c = line.split(',')\n",
    "            names.append(n)\n",
    "            classes.append(c)\n",
    "    return np.array(names), np.array(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17000 training examples.\n",
      "5149 testing examples.\n"
     ]
    }
   ],
   "source": [
    "names, labels = process_file('train_labels.txt')\n",
    "labels = np.array([int(x) for x in labels])\n",
    "names = np.array(names)\n",
    "eval_names, _ = process_file('sample_submission.txt')\n",
    "print(f\"{len(names)} training examples.\")\n",
    "print(f\"{len(eval_names)} testing examples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(name):\n",
    "    img = cv2.imread(f\"data/{name}.png\")\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_process_image(name, verbose=False):\n",
    "    import math\n",
    "    img = read_image(name)\n",
    "    (h, w) = img.shape[:2]\n",
    "    blurred = cv2.medianBlur(img, 7)\n",
    "    _, thresh = cv2.threshold(blurred, np.min(blurred) + 10, 255, cv2.THRESH_BINARY)\n",
    "    thresh_small = cv2.resize(thresh, (thresh.shape[0], thresh.shape[1]), cv2.INTER_NEAREST)\n",
    "    _, labels, stats, _ = cv2.connectedComponentsWithStats(thresh_small, 8, cv2.CV_32S)\n",
    "    chosen_comps = [idx for idx, stat in enumerate(stats) if stat[4] > 2000 and idx != 0]\n",
    "    thresh_clean = np.zeros_like(thresh)\n",
    "    for comp in chosen_comps:\n",
    "        thresh_clean[labels == comp] = 255\n",
    "    coords = np.column_stack(np.where(thresh_clean > 0)).astype(np.float32)\n",
    "    \n",
    "    img_cropped = None\n",
    "#     try:\n",
    "#         coords = np.column_stack(np.where(thresh_clean > 0)).astype(np.float32)\n",
    "#         mean, eigenvectors = cv2.PCACompute(coords, mean=None)\n",
    "#         angle = math.asin(eigenvectors[0][0]) / math.atan(1.0) * 45\n",
    "#         print(eigenvectors)\n",
    "        # find contours / rectangle\n",
    "    try:\n",
    "        contours, _ = cv2.findContours(thresh_clean, 1, 1)\n",
    "        angle = cv2.minAreaRect(contours[0])[2]\n",
    "        if angle < -45:\n",
    "            angle += 90\n",
    "        if angle > 45:\n",
    "            angle -= 90\n",
    "        M = cv2.getRotationMatrix2D((h/2, w/2), angle, 1)\n",
    "        thresh_rot = cv2.warpAffine(thresh_clean, M, (w, h))\n",
    "        coords = np.column_stack(np.where(thresh_rot > 0)).astype(np.float32)\n",
    "        rect = cv2.boundingRect(coords)\n",
    "        rot = cv2.warpAffine(img, M, (w, h), \n",
    "                             flags=cv2.INTER_CUBIC,\n",
    "                             borderMode=cv2.BORDER_REPLICATE)\n",
    "        cropped = rot[ \n",
    "            rect[0]:(rect[0]+rect[2]),\n",
    "            rect[1]:(rect[1]+rect[3]),\n",
    "        ]\n",
    "        cropped = cv2.resize(cropped, (img.shape[0], img.shape[1]))\n",
    "    except IndexError:\n",
    "        cropped = img\n",
    "        \n",
    "        \n",
    "#         print(angle)\n",
    "#         if angle > 45:\n",
    "#             angle -= 90\n",
    "#         print(angle)\n",
    "#         M = cv2.getRotationMatrix2D(tuple(np.ravel(mean)), angle, scale=1.)\n",
    "#         rotated = cv2.warpAffine(img, M, (w, h),\n",
    "#                                  flags=cv2.INTER_CUBIC, \n",
    "#                                  borderMode=cv2.BORDER_REPLICATE)\n",
    "#     except:\n",
    "#         rotated = img\n",
    "    \n",
    "#     try:\n",
    "#         stat = list(sorted(stats, key=lambda x: x[4], reverse=True))[1]\n",
    "#         cropped = img[stat[1]:(stat[1]+stat[3]), stat[0]:(stat[0]+stat[2])]\n",
    "#         cropped = cv2.resize(cropped, (img.shape[0], img.shape[1]))\n",
    "#     except IndexError:\n",
    "#         cropped = img\n",
    "        \n",
    "    if verbose:\n",
    "        print(name)\n",
    "        plt.subplot(1, 5, 1)\n",
    "        plt.imshow(img)\n",
    "        plt.subplot(1, 5, 2)\n",
    "        plt.imshow(blurred)\n",
    "        plt.subplot(1, 5, 3)\n",
    "        plt.imshow(thresh)\n",
    "        plt.subplot(1, 5, 4)\n",
    "        plt.imshow(thresh_clean)\n",
    "        plt.subplot(1, 5, 5)\n",
    "        plt.imshow(cropped)\n",
    "        plt.show()\n",
    "    \n",
    "    return cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "014842\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_name = np.random.choice(names)\n",
    "# img_name = '003252'\n",
    "_ = read_and_process_image(img_name, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 224, 224, 1)\n",
      "(3000,)\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "for name in names[:3000]:\n",
    "    img = read_and_process_image(name)\n",
    "    img = img / 255.\n",
    "    img -= np.mean(img)\n",
    "    X.append(img)\n",
    "X = np.array(X, dtype=np.float32)\n",
    "X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)\n",
    "y = np.array(labels[:3000], dtype=np.float32)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as tfk\n",
    "import tensorflow.keras.layers as tfkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    import tensorflow.keras.backend as K\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss(y_true, y_pred):\n",
    "    import tensorflow.keras.backend as K\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return 1 - f1\n",
    "\n",
    "model = tfk.Sequential()\n",
    "\n",
    "#model.add(tfkl.Conv2D(16, kernel_size=8, strides=1, activation='relu'))\n",
    "#model.add(tfkl.Dropout(0.3))\n",
    "#model.add(tfkl.Conv2D(16, kernel_size=5, strides=1, activation='relu'))\n",
    "#model.add(tfkl.Dropout(0.3))\n",
    "model.add(tfkl.Conv2D(16, kernel_size=5, strides=1, activation='relu'))\n",
    "model.add(tfkl.MaxPooling2D())\n",
    "\n",
    "model.add(tfkl.Conv2D(16, kernel_size=3, strides=1, activation='relu'))\n",
    "model.add(tfkl.Dropout(0.3))\n",
    "model.add(tfkl.MaxPooling2D())\n",
    "\n",
    "model.add(tfkl.Conv2D(8, kernel_size=3, strides=1, activation='relu'))\n",
    "model.add(tfkl.Dropout(0.3))\n",
    "model.add(tfkl.MaxPooling2D())\n",
    "\n",
    "model.add(tfkl.Flatten())\n",
    "model.add(tfkl.Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = tfk.optimizers.Adam()\n",
    "model.build(input_shape=X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_layer(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
    "\n",
    "    # Arguments\n",
    "        inputs (tensor): input tensor from input image or previous layer\n",
    "        num_filters (int): Conv2D number of filters\n",
    "        kernel_size (int): Conv2D square kernel dimensions\n",
    "        strides (int): Conv2D square stride dimensions\n",
    "        activation (string): activation name\n",
    "        batch_normalization (bool): whether to include batch normalization\n",
    "        conv_first (bool): conv-bn-activation (True) or\n",
    "            bn-activation-conv (False)\n",
    "\n",
    "    # Returns\n",
    "        x (tensor): tensor as input to the next layer\n",
    "    \"\"\"\n",
    "    conv = tfkl.Conv2D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=tfk.regularizers.l2(1e-4))\n",
    "\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = tfkl.BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = tfkl.Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = tfkl.BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = tfkl.Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x\n",
    "\n",
    "def resnet_v2(input_shape, depth):\n",
    "    \"\"\"ResNet Version 2 Model builder [b]\n",
    "\n",
    "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
    "    bottleneck layer\n",
    "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
    "    Second and onwards shortcut connection is identity.\n",
    "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
    "    by a convolutional layer with strides=2, while the number of filter maps is\n",
    "    doubled. Within each stage, the layers have the same number filters and the\n",
    "    same filter map sizes.\n",
    "    Features maps sizes:\n",
    "    conv1  : 32x32,  16\n",
    "    stage 0: 32x32,  64\n",
    "    stage 1: 16x16, 128\n",
    "    stage 2:  8x8,  256\n",
    "\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 9 != 0:\n",
    "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
    "    # Start model definition.\n",
    "    num_filters_in = 16\n",
    "    num_res_blocks = int((depth - 2) / 9)\n",
    "\n",
    "    inputs = tfkl.Input(shape=input_shape)\n",
    "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
    "    x = resnet_layer(inputs=inputs,\n",
    "                     num_filters=num_filters_in,\n",
    "                     conv_first=True)\n",
    "\n",
    "    # Instantiate the stack of residual units\n",
    "    for stage in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            activation = 'relu'\n",
    "            batch_normalization = True\n",
    "            strides = 1\n",
    "            if stage == 0:\n",
    "                num_filters_out = num_filters_in * 4\n",
    "                if res_block == 0:  # first layer and first stage\n",
    "                    activation = None\n",
    "                    batch_normalization = False\n",
    "            else:\n",
    "                num_filters_out = num_filters_in * 2\n",
    "                if res_block == 0:  # first layer but not first stage\n",
    "                    strides = 2    # downsample\n",
    "\n",
    "            # bottleneck residual unit\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters_in,\n",
    "                             kernel_size=1,\n",
    "                             strides=strides,\n",
    "                             activation=activation,\n",
    "                             batch_normalization=batch_normalization,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_in,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_out,\n",
    "                             kernel_size=1,\n",
    "                             conv_first=False)\n",
    "            if res_block == 0:\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters_out,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = tfkl.add([x, y])\n",
    "\n",
    "        num_filters_in = num_filters_out\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v2 has BN-ReLU before Pooling\n",
    "    x = tfkl.BatchNormalization()(x)\n",
    "    x = tfkl.Activation('relu')(x)\n",
    "    x = tfkl.AveragePooling2D(pool_size=8)(x)\n",
    "    y = tfkl.Flatten()(x)\n",
    "    outputs = tfkl.Dense(1,\n",
    "                    activation='sigmoid',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = tfk.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = resnet_v2(input_shape=X.shape[1:], depth=47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            multiple                  416       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            multiple                  2320      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            multiple                  1160      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  5409      \n",
      "=================================================================\n",
      "Total params: 9,305\n",
      "Trainable params: 9,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tfk.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, images, labels, batch_size=32, shuffle=True, batch_count=1):\n",
    "        'Initialization'\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.shuffle = shuffle\n",
    "        self.images = images\n",
    "        self.batch_count = batch_count\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return self.batch_count\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        print(f\"__getitem__ {index}\")\n",
    "        'Updates indexes after each epoch'\n",
    "        pos_indexes = np.where(self.labels == 1.)\n",
    "        neg_indexes = np.where(self.labels == 0.)\n",
    "        \n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(pos_indexes)\n",
    "            np.random.shuffle(neg_indexes)\n",
    "        \n",
    "        print(f\"__shuffle__ {index}\")\n",
    "        \n",
    "        indexes = np.ravel(np.column_stack([\n",
    "            pos_indexes[:self.batch_size//2],\n",
    "            neg_indexes[:self.batch_size//2],\n",
    "        ]))\n",
    "        \n",
    "        X = self.images[indexes]\n",
    "        X = X.reshape(X.shape[:3] + (1,))\n",
    "        y = self.labels[indexes]\n",
    "        \n",
    "        print(X.shape)\n",
    "        print(y.shape)\n",
    "\n",
    "        return X, y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weight(y):\n",
    "    pos = np.sum(y == 1)\n",
    "    neg = np.sum(y == 0)\n",
    "    total = y.shape[0]\n",
    "    weight_for_0 = (1 / neg)*(total)/2.0 \n",
    "    weight_for_1 = (1 / pos)*(total)/2.0\n",
    "\n",
    "    class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "    return class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2250 samples, validate on 750 samples\n",
      "Epoch 1/100\n",
      "2250/2250 [==============================] - 31s 14ms/sample - loss: 0.6086 - f1: 0.3807 - accuracy: 0.6164 - val_loss: 0.5958 - val_f1: 0.4484 - val_accuracy: 0.7680\n",
      "Epoch 2/100\n",
      "2250/2250 [==============================] - 31s 14ms/sample - loss: 0.5504 - f1: 0.4379 - accuracy: 0.6733 - val_loss: 0.5591 - val_f1: 0.3645 - val_accuracy: 0.5813\n",
      "Epoch 3/100\n",
      "2250/2250 [==============================] - 48s 21ms/sample - loss: 0.5281 - f1: 0.4488 - accuracy: 0.6929 - val_loss: 0.5639 - val_f1: 0.4289 - val_accuracy: 0.8027\n",
      "Epoch 4/100\n",
      "2250/2250 [==============================] - 43s 19ms/sample - loss: 0.5101 - f1: 0.4769 - accuracy: 0.7218 - val_loss: 0.5517 - val_f1: 0.4222 - val_accuracy: 0.7040\n",
      "Epoch 5/100\n",
      "2250/2250 [==============================] - 39s 17ms/sample - loss: 0.4808 - f1: 0.4822 - accuracy: 0.7462 - val_loss: 0.5588 - val_f1: 0.4352 - val_accuracy: 0.7533\n",
      "Epoch 6/100\n",
      "2250/2250 [==============================] - 40s 18ms/sample - loss: 0.4609 - f1: 0.5043 - accuracy: 0.7649 - val_loss: 0.5476 - val_f1: 0.4262 - val_accuracy: 0.7253\n",
      "Epoch 7/100\n",
      "2250/2250 [==============================] - 39s 17ms/sample - loss: 0.4367 - f1: 0.5460 - accuracy: 0.7787 - val_loss: 0.5723 - val_f1: 0.3867 - val_accuracy: 0.7653\n",
      "Epoch 8/100\n",
      "2250/2250 [==============================] - 37s 16ms/sample - loss: 0.4147 - f1: 0.5401 - accuracy: 0.7782 - val_loss: 0.6229 - val_f1: 0.3040 - val_accuracy: 0.8373\n",
      "Epoch 9/100\n",
      "2250/2250 [==============================] - 37s 16ms/sample - loss: 0.4282 - f1: 0.5506 - accuracy: 0.7862 - val_loss: 0.5970 - val_f1: 0.3895 - val_accuracy: 0.7893\n",
      "Epoch 10/100\n",
      "2250/2250 [==============================] - 37s 16ms/sample - loss: 0.3702 - f1: 0.6018 - accuracy: 0.8204 - val_loss: 0.5859 - val_f1: 0.4104 - val_accuracy: 0.6947\n",
      "Epoch 11/100\n",
      "2240/2250 [============================>.] - ETA: 0s - loss: 0.3530 - f1: 0.6182 - accuracy: 0.8313Restoring model weights from the end of the best epoch.\n",
      "2250/2250 [==============================] - 37s 16ms/sample - loss: 0.3526 - f1: 0.6189 - accuracy: 0.8311 - val_loss: 0.5680 - val_f1: 0.4049 - val_accuracy: 0.6827\n",
      "Epoch 00011: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14953f050>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=[f1, 'accuracy'])\n",
    "early_stopping = tfk.callbacks.EarlyStopping(\n",
    "    monitor='val_f1', \n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    mode='max',\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "lr_reducer = tfk.callbacks.ReduceLROnPlateau(\n",
    "    factor=np.sqrt(0.1),\n",
    "    cooldown=0,\n",
    "    patience=5,\n",
    "    min_lr=0.5e-6,\n",
    ")\n",
    "model.fit(\n",
    "    X, y, \n",
    "    batch_size=32, \n",
    "    epochs=100, \n",
    "    class_weight=get_class_weight(y), \n",
    "    callbacks = [lr_reducer, early_stopping],\n",
    "    validation_split=0.25,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, epochs=1):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "    dataset = dataset.shuffle(1000).batch(32)\n",
    "    print(f\"{X_train.shape[0]} training examples, {X_test.shape[0]} validation.\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f'Epoch {epoch} started.')\n",
    "        loss_history = []\n",
    "        for (batch, (images, labels)) in enumerate(dataset):\n",
    "            if labels.numpy().sum() == 0:\n",
    "                print('Skipping batch -- no positive examples.')\n",
    "                \n",
    "            with tf.GradientTape() as tape:\n",
    "                logits = model(images, training=True)\n",
    "                loss_value = f1_loss(labels, logits)\n",
    "                loss = loss_value.numpy().mean()\n",
    "                loss_history.append(loss)\n",
    "                grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "                optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "            \n",
    "        print(f'Epoch {epoch} finished.')\n",
    "        print(f\"Loss: {np.mean(loss_history)}\")\n",
    "        y_pred = tf.math.round(model(X_test))\n",
    "        print(f\"Validation f1: {f1(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(X, y, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)\n",
    "print(y_pred)\n",
    "print(np.mean(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
