{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(file):\n",
    "    classes = []\n",
    "    names = []\n",
    "    with open(file, 'r') as f:\n",
    "        header = True\n",
    "        for line in f:\n",
    "            if header:\n",
    "                header = False\n",
    "                continue\n",
    "            n, c = line.split(',')\n",
    "            names.append(n)\n",
    "            classes.append(c)\n",
    "    return np.array(names), np.array(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17000 training examples.\n",
      "5149 testing examples.\n"
     ]
    }
   ],
   "source": [
    "names, labels = process_file('train_labels.txt')\n",
    "labels = np.array([int(x) for x in labels])\n",
    "names = np.array(names)\n",
    "eval_names, _ = process_file('sample_submission.txt')\n",
    "print(f\"{len(names)} training examples.\")\n",
    "print(f\"{len(eval_names)} testing examples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(name):\n",
    "    img = cv2.imread(f\"data/{name}.png\")\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_process_image(name, verbose=False):\n",
    "    import math\n",
    "    img = read_image(name)\n",
    "    (h, w) = img.shape[:2]\n",
    "    blurred = cv2.medianBlur(img, 7)\n",
    "    _, thresh = cv2.threshold(blurred, np.min(blurred) + 10, 255, cv2.THRESH_BINARY)\n",
    "    thresh_small = cv2.resize(thresh, (thresh.shape[0], thresh.shape[1]), cv2.INTER_NEAREST)\n",
    "    _, labels, stats, _ = cv2.connectedComponentsWithStats(thresh_small, 8, cv2.CV_32S)\n",
    "    chosen_comps = [idx for idx, stat in enumerate(stats) if stat[4] > 2000 and idx != 0]\n",
    "    thresh_clean = np.zeros_like(thresh)\n",
    "    for comp in chosen_comps:\n",
    "        thresh_clean[labels == comp] = 255\n",
    "    coords = np.column_stack(np.where(thresh_clean > 0)).astype(np.float32)\n",
    "    \n",
    "    img_cropped = None\n",
    "#     try:\n",
    "#         coords = np.column_stack(np.where(thresh_clean > 0)).astype(np.float32)\n",
    "#         mean, eigenvectors = cv2.PCACompute(coords, mean=None)\n",
    "#         angle = math.asin(eigenvectors[0][0]) / math.atan(1.0) * 45\n",
    "#         print(eigenvectors)\n",
    "        # find contours / rectangle\n",
    "    try:\n",
    "        contours, _ = cv2.findContours(thresh_clean, 1, 1)\n",
    "        angle = cv2.minAreaRect(contours[0])[2]\n",
    "        if angle < -45:\n",
    "            angle += 90\n",
    "        if angle > 45:\n",
    "            angle -= 90\n",
    "        M = cv2.getRotationMatrix2D((h/2, w/2), angle, 1)\n",
    "        thresh_rot = cv2.warpAffine(thresh_clean, M, (w, h))\n",
    "        coords = np.column_stack(np.where(thresh_rot > 0)).astype(np.float32)\n",
    "        rect = cv2.boundingRect(coords)\n",
    "        rot = cv2.warpAffine(img, M, (w, h), \n",
    "                             flags=cv2.INTER_CUBIC,\n",
    "                             borderMode=cv2.BORDER_REPLICATE)\n",
    "        cropped = rot[ \n",
    "            rect[0]:(rect[0]+rect[2]),\n",
    "            rect[1]:(rect[1]+rect[3]),\n",
    "        ]\n",
    "        cropped = cv2.resize(cropped, (img.shape[0], img.shape[1]))\n",
    "    except IndexError:\n",
    "        cropped = img\n",
    "        \n",
    "        \n",
    "#         print(angle)\n",
    "#         if angle > 45:\n",
    "#             angle -= 90\n",
    "#         print(angle)\n",
    "#         M = cv2.getRotationMatrix2D(tuple(np.ravel(mean)), angle, scale=1.)\n",
    "#         rotated = cv2.warpAffine(img, M, (w, h),\n",
    "#                                  flags=cv2.INTER_CUBIC, \n",
    "#                                  borderMode=cv2.BORDER_REPLICATE)\n",
    "#     except:\n",
    "#         rotated = img\n",
    "    \n",
    "#     try:\n",
    "#         stat = list(sorted(stats, key=lambda x: x[4], reverse=True))[1]\n",
    "#         cropped = img[stat[1]:(stat[1]+stat[3]), stat[0]:(stat[0]+stat[2])]\n",
    "#         cropped = cv2.resize(cropped, (img.shape[0], img.shape[1]))\n",
    "#     except IndexError:\n",
    "#         cropped = img\n",
    "        \n",
    "    if verbose:\n",
    "        print(name)\n",
    "        plt.subplot(1, 5, 1)\n",
    "        plt.imshow(img)\n",
    "        plt.subplot(1, 5, 2)\n",
    "        plt.imshow(blurred)\n",
    "        plt.subplot(1, 5, 3)\n",
    "        plt.imshow(thresh)\n",
    "        plt.subplot(1, 5, 4)\n",
    "        plt.imshow(thresh_clean)\n",
    "        plt.subplot(1, 5, 5)\n",
    "        plt.imshow(cropped)\n",
    "        plt.show()\n",
    "    \n",
    "    return cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "007505\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_name = np.random.choice(names)\n",
    "# img_name = '003252'\n",
    "_ = read_and_process_image(img_name, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 224, 224, 1)\n",
      "(3000,)\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "for name in names[:3000]:\n",
    "    img = read_and_process_image(name)\n",
    "    X.append(img)\n",
    "X = np.array(X, dtype=np.float32)\n",
    "X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)\n",
    "y = np.array(labels[:3000], dtype=np.float32)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as tfk\n",
    "import tensorflow.keras.layers as tfkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            multiple                  416       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            multiple                  2320      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            multiple                  1160      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 multiple                  0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  5409      \n",
      "=================================================================\n",
      "Total params: 9,305\n",
      "Trainable params: 9,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    import tensorflow.keras.backend as K\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss(y_true, y_pred):\n",
    "    import tensorflow.keras.backend as K\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return 1 - f1\n",
    "\n",
    "model = tfk.Sequential()\n",
    "\n",
    "#model.add(tfkl.Conv2D(16, kernel_size=8, strides=1, activation='relu'))\n",
    "#model.add(tfkl.Dropout(0.3))\n",
    "#model.add(tfkl.Conv2D(16, kernel_size=5, strides=1, activation='relu'))\n",
    "#model.add(tfkl.Dropout(0.3))\n",
    "model.add(tfkl.Conv2D(16, kernel_size=5, strides=1, activation='relu'))\n",
    "model.add(tfkl.MaxPooling2D())\n",
    "\n",
    "model.add(tfkl.Conv2D(16, kernel_size=3, strides=1, activation='relu'))\n",
    "model.add(tfkl.Dropout(0.3))\n",
    "model.add(tfkl.MaxPooling2D())\n",
    "\n",
    "model.add(tfkl.Conv2D(8, kernel_size=3, strides=1, activation='relu'))\n",
    "model.add(tfkl.Dropout(0.3))\n",
    "model.add(tfkl.MaxPooling2D())\n",
    "\n",
    "model.add(tfkl.Flatten())\n",
    "model.add(tfkl.Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = tfk.optimizers.Adam()\n",
    "model.build(input_shape=X.shape)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_layer(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
    "\n",
    "    # Arguments\n",
    "        inputs (tensor): input tensor from input image or previous layer\n",
    "        num_filters (int): Conv2D number of filters\n",
    "        kernel_size (int): Conv2D square kernel dimensions\n",
    "        strides (int): Conv2D square stride dimensions\n",
    "        activation (string): activation name\n",
    "        batch_normalization (bool): whether to include batch normalization\n",
    "        conv_first (bool): conv-bn-activation (True) or\n",
    "            bn-activation-conv (False)\n",
    "\n",
    "    # Returns\n",
    "        x (tensor): tensor as input to the next layer\n",
    "    \"\"\"\n",
    "    conv = tfkl.Conv2D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=tfk.regularizers.l2(1e-4))\n",
    "\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = tfkl.BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = tfkl.Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = tfkl.BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = tfkl.Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x\n",
    "\n",
    "def resnet_v2(input_shape, depth):\n",
    "    \"\"\"ResNet Version 2 Model builder [b]\n",
    "\n",
    "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
    "    bottleneck layer\n",
    "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
    "    Second and onwards shortcut connection is identity.\n",
    "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
    "    by a convolutional layer with strides=2, while the number of filter maps is\n",
    "    doubled. Within each stage, the layers have the same number filters and the\n",
    "    same filter map sizes.\n",
    "    Features maps sizes:\n",
    "    conv1  : 32x32,  16\n",
    "    stage 0: 32x32,  64\n",
    "    stage 1: 16x16, 128\n",
    "    stage 2:  8x8,  256\n",
    "\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 9 != 0:\n",
    "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
    "    # Start model definition.\n",
    "    num_filters_in = 16\n",
    "    num_res_blocks = int((depth - 2) / 9)\n",
    "\n",
    "    inputs = tfkl.Input(shape=input_shape)\n",
    "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
    "    x = resnet_layer(inputs=inputs,\n",
    "                     num_filters=num_filters_in,\n",
    "                     conv_first=True)\n",
    "\n",
    "    # Instantiate the stack of residual units\n",
    "    for stage in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            activation = 'relu'\n",
    "            batch_normalization = True\n",
    "            strides = 1\n",
    "            if stage == 0:\n",
    "                num_filters_out = num_filters_in * 4\n",
    "                if res_block == 0:  # first layer and first stage\n",
    "                    activation = None\n",
    "                    batch_normalization = False\n",
    "            else:\n",
    "                num_filters_out = num_filters_in * 2\n",
    "                if res_block == 0:  # first layer but not first stage\n",
    "                    strides = 2    # downsample\n",
    "\n",
    "            # bottleneck residual unit\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters_in,\n",
    "                             kernel_size=1,\n",
    "                             strides=strides,\n",
    "                             activation=activation,\n",
    "                             batch_normalization=batch_normalization,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_in,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_out,\n",
    "                             kernel_size=1,\n",
    "                             conv_first=False)\n",
    "            if res_block == 0:\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters_out,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = tfkl.add([x, y])\n",
    "\n",
    "        num_filters_in = num_filters_out\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v2 has BN-ReLU before Pooling\n",
    "    x = tfkl.BatchNormalization()(x)\n",
    "    x = tfkl.Activation('relu')(x)\n",
    "    x = tfkl.AveragePooling2D(pool_size=8)(x)\n",
    "    y = tfkl.Flatten()(x)\n",
    "    outputs = tfkl.Dense(1,\n",
    "                    activation='sigmoid',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = tfk.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet_v2(input_shape=X.shape[1:], depth=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tfk.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, images, labels, batch_size=32, shuffle=True, batch_count=1):\n",
    "        'Initialization'\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.shuffle = shuffle\n",
    "        self.images = images\n",
    "        self.batch_count = batch_count\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return self.batch_count\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        print(f\"__getitem__ {index}\")\n",
    "        'Updates indexes after each epoch'\n",
    "        pos_indexes = np.where(self.labels == 1.)\n",
    "        neg_indexes = np.where(self.labels == 0.)\n",
    "        \n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(pos_indexes)\n",
    "            np.random.shuffle(neg_indexes)\n",
    "        \n",
    "        print(f\"__shuffle__ {index}\")\n",
    "        \n",
    "        indexes = np.ravel(np.column_stack([\n",
    "            pos_indexes[:self.batch_size//2],\n",
    "            neg_indexes[:self.batch_size//2],\n",
    "        ]))\n",
    "        \n",
    "        X = self.images[indexes]\n",
    "        X = X.reshape(X.shape[:3] + (1,))\n",
    "        y = self.labels[indexes]\n",
    "        \n",
    "        print(X.shape)\n",
    "        print(y.shape)\n",
    "\n",
    "        return X, y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weight(y):\n",
    "    pos = np.sum(y == 1)\n",
    "    neg = np.sum(y == 0)\n",
    "    total = y.shape[0]\n",
    "    weight_for_0 = (1 / neg)*(total)/2.0 \n",
    "    weight_for_1 = (1 / pos)*(total)/2.0\n",
    "\n",
    "    class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "    return class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2250 samples, validate on 750 samples\n",
      "Epoch 1/100\n",
      "2250/2250 [==============================] - 440s 196ms/sample - loss: 1.2530 - f1: 0.3785 - accuracy: 0.6689 - val_loss: 2.7919 - val_f1: 0.2761 - val_accuracy: 0.2840\n",
      "Epoch 2/100\n",
      "2250/2250 [==============================] - 496s 221ms/sample - loss: 0.8079 - f1: 0.4488 - accuracy: 0.7129 - val_loss: 1.1385 - val_f1: 0.3317 - val_accuracy: 0.4547\n",
      "Epoch 3/100\n",
      "  64/2250 [..............................] - ETA: 7:26 - loss: 0.6325 - f1: 0.5278 - accuracy: 0.7188"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=[f1, 'accuracy'])\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_f1', \n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    mode='max',\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "lr_reducer = ReduceLROnPlateau(\n",
    "    factor=np.sqrt(0.1),\n",
    "    cooldown=0,\n",
    "    patience=5,\n",
    "    min_lr=0.5e-6,\n",
    ")\n",
    "model.fit(\n",
    "    X, y, \n",
    "    batch_size=32, \n",
    "    epochs=100, \n",
    "    class_weight=get_class_weight(y), \n",
    "    callbacks = [lr_reduces, early_stopping],\n",
    "    validation_split=0.25,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, epochs=1):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "    dataset = dataset.shuffle(1000).batch(32)\n",
    "    print(f\"{X_train.shape[0]} training examples, {X_test.shape[0]} validation.\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f'Epoch {epoch} started.')\n",
    "        loss_history = []\n",
    "        for (batch, (images, labels)) in enumerate(dataset):\n",
    "            if labels.numpy().sum() == 0:\n",
    "                print('Skipping batch -- no positive examples.')\n",
    "                \n",
    "            with tf.GradientTape() as tape:\n",
    "                logits = model(images, training=True)\n",
    "                loss_value = f1_loss(labels, logits)\n",
    "                loss = loss_value.numpy().mean()\n",
    "                loss_history.append(loss)\n",
    "                grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "                optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "            \n",
    "        print(f'Epoch {epoch} finished.')\n",
    "        print(f\"Loss: {np.mean(loss_history)}\")\n",
    "        y_pred = tf.math.round(model(X_test))\n",
    "        print(f\"Validation f1: {f1(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(X, y, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)\n",
    "print(y_pred)\n",
    "print(np.mean(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
